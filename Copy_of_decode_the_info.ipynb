{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnh7d1MkA2sW",
        "outputId": "ae98f4cd-0f42-4387-a9c5-f0465abafb86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\ashu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.28.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ashu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashu\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2022.12.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# !pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LUI1aZimAYdz"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import librosa.display\n",
        "import requests\n",
        "import sys\n",
        "import pprint\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVIIX8rDavwp",
        "outputId": "7647b189-7f40-4b00-e48d-d53209578ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_LYdSbsxYDP"
      },
      "source": [
        "**data generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kVHiBxxA-pn0"
      },
      "outputs": [],
      "source": [
        "# train_data = pd.DataFrame()\n",
        "files = []\n",
        "path = os.getcwd() + \"/train_data\"\n",
        "filelist = os.listdir(path) \n",
        "for file in filelist:\n",
        "  ext = file.split('_')[0]\n",
        "  if ext=='audio':\n",
        "    files.append(file)\n",
        "train_data = pd.DataFrame(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>audio_class_1.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>audio_class_2.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0\n",
              "0  audio_class_1.wav\n",
              "1  audio_class_2.wav"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5Louv77Qdqt"
      },
      "outputs": [],
      "source": [
        "files = []\n",
        "path = os.getcwd() + \"/drive/MyDrive/sample_data/\"\n",
        "filelist = os.listdir(path) \n",
        "for file in filelist:\n",
        "  ext = file.split('_')[0]\n",
        "  if ext=='test':\n",
        "    files.append(file)\n",
        "test_data = pd.DataFrame(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HvrekEyyRpK"
      },
      "outputs": [],
      "source": [
        "# path1 = path+train_data[0][0]\n",
        "# auth_key = '49a48a6afe8640b5a2cae8954a5d5953'\n",
        "# headers = {\"authorization\": auth_key, \"content-type\": \"application/json\"}\n",
        "# def read_file(path1):\n",
        "#    with open(path1, 'rb') as _file:\n",
        "#        while True:\n",
        "#            data = _file.read(5242880)\n",
        "#            if not data:\n",
        "#                break\n",
        "#            yield data\n",
        " \n",
        "# upload_response = requests.post('https://api.assemblyai.com/v2/upload', headers=headers, data=read_file(path+train_data[0][0]))\n",
        "# audio_url = upload_response.json()[\"upload_url\"]\n",
        "# transcript_request = {'audio_url': audio_url}\n",
        "# transcript_response = requests.post(\"https://api.assemblyai.com/v2/transcript\", json=transcript_request, headers=headers)\n",
        "# _id = transcript_response.json()[\"id\"]\n",
        "\n",
        "\n",
        "\n",
        "# polling_response = requests.get(\"https://api.assemblyai.com/v2/transcript/\" + _id, headers=headers)\n",
        "# if polling_response.json()['status'] != 'completed':\n",
        "#    print(polling_response.json())\n",
        "# else:\n",
        "#    with open(_id + '.txt', 'w') as f:\n",
        "#        f.write(polling_response.json()['text'])\n",
        "#    print('Transcript saved to', _id, '.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fEOrAjQziug",
        "outputId": "4dd814a1-b35d-47cc-fc04-0d328fb8510d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting configure\n",
            "  Downloading configure-0.5.tar.gz (6.2 kB)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
            "Using legacy 'setup.py install' for configure, since package 'wheel' is not installed.\n",
            "Installing collected packages: pyyaml, configure\n",
            "    Running setup.py install for configure: started\n",
            "    Running setup.py install for configure: finished with status 'done'\n",
            "Successfully installed configure-0.5 pyyaml-6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# !pip install configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "aP_U-CQ63pxh",
        "outputId": "b359bdc4-9790-4ef8-f607-200d1e4d1462"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>audio_class_1.wav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>audio_class_2.wav</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0\n",
              "0  audio_class_1.wav\n",
              "1  audio_class_2.wav"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "udSR7ZTTyhaV"
      },
      "outputs": [],
      "source": [
        "# def convertToText(pathToFile):\n",
        "#   # from configure import auth_key\n",
        "#   # store global constants\n",
        "#   headers = {\n",
        "#     \"authorization\": auth_key,\n",
        "#     \"content-type\": \"application/json\"\n",
        "#   }\n",
        "#   transcript_endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
        "#   upload_endpoint = 'https://api.assemblyai.com/v2/upload'\n",
        "  \n",
        "#   # make a function to pass the mp3 to the upload endpoint\n",
        "#   def read_file(filename):\n",
        "#     with open(filename, 'rb') as _file:\n",
        "#         while True:\n",
        "#             data = _file.read(5242880)\n",
        "#             if not data:\n",
        "#                 break\n",
        "#             yield data\n",
        "  \n",
        "#   # upload our audio file\n",
        "#   upload_response = requests.post(\n",
        "#     upload_endpoint,\n",
        "#     headers=headers, data=read_file(pathToFile)\n",
        "#   )\n",
        "#   print('Audio file uploaded')\n",
        "  \n",
        "#   # send a request to transcribe the audio file\n",
        "#   transcript_request = {'audio_url': upload_response.json()['upload_url']}\n",
        "#   transcript_response = requests.post(transcript_endpoint, json=transcript_request, headers=headers)\n",
        "#   # print('Transcription Requested')\n",
        "#   # pprint.pprint(transcript_response.json())\n",
        "#   # set up polling\n",
        "#   polling_response = requests.get(transcript_endpoint+\"/\"+transcript_response.json()['id'], headers=headers)\n",
        "#   filename = transcript_response.json()['id'] + '.txt'\n",
        "#   # if our status isn’t complete, sleep and then poll again\n",
        "#   while polling_response.json()['status'] != 'completed':\n",
        "#     # sleep(30)\n",
        "#     polling_response = requests.get(transcript_endpoint+\"/\"+transcript_response.json()['id'], headers=headers)\n",
        "#     # print(\"File is\", polling_response.json()['status'])\n",
        "#   with open(filename, 'w') as f:\n",
        "#     f.write(polling_response.json()['text'])\n",
        "#   f = open(os.getcwd()+'/'+filename, \"r\")\n",
        "#   print(f.read()) \n",
        "#   # print('Transcript saved to', filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mM-R5MffAu1y"
      },
      "outputs": [],
      "source": [
        "def extract_features(files,n_mfcc=180):\n",
        "  file_name = os.path.join(path+str(files))\n",
        "\n",
        "  y, sampling_rate = librosa.load(file_name,res_type='kaiser_fast')\n",
        "  print(\"Sampling rate is : \",sampling_rate)\n",
        "  # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
        "  mfccs = np.mean(librosa.feature.mfcc(y, sr=sampling_rate, n_mfcc=180).T,axis=0)\n",
        "  # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
        "  # stft = np.abs(librosa.stft(y))\n",
        "  # # Computes a chromagram from a waveform or power spectrogram.\n",
        "  # chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampling_rate).T,axis=0)\n",
        "  # # Computes a mel-scaled spectrogram.\n",
        "  # mel = np.mean(librosa.feature.melspectrogram(y, sr=sampling_rate).T,axis=0)\n",
        "  # # Computes spectral contrast\n",
        "  # contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sampling_rate).T,axis=0)\n",
        "  # # Computes the tonal centroid features (tonnetz)\n",
        "  # tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y),sr=sampling_rate).T,axis=0)\n",
        "  # We add also the classes of each file as a label at the end\n",
        "  # label = files.label\n",
        "  return (y,mfccs)  #, chroma, mel, contrast, tonnetz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbi0YqH30R3E",
        "outputId": "e9d26ad7-73c0-4977-8a7d-811d00a94c0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ashu\\AppData\\Local\\Temp\\ipykernel_12164\\2848282869.py:4: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sampling_rate = librosa.load(file_name,res_type='kaiser_fast')\n",
            "c:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\ashu\\\\Desktop\\\\voice-classifier/train_dataaudio_class_1.wav'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[0;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
            "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'c:\\\\Users\\\\ashu\\\\Desktop\\\\voice-classifier/train_dataaudio_class_1.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_data[\u001b[39m0\u001b[39m]:\n\u001b[0;32m      4\u001b[0m   names\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(x))\n\u001b[1;32m----> 5\u001b[0m   features\u001b[39m.\u001b[39mappend(extract_features(x))\n\u001b[0;32m      6\u001b[0m train_data[\u001b[39m'\u001b[39m\u001b[39mmfcc\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mfeatures\n",
            "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(files, n_mfcc)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_features\u001b[39m(files,n_mfcc\u001b[39m=\u001b[39m\u001b[39m180\u001b[39m):\n\u001b[0;32m      2\u001b[0m   file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(files))\n\u001b[1;32m----> 4\u001b[0m   y, sampling_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(file_name,res_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mkaiser_fast\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSampling rate is : \u001b[39m\u001b[39m\"\u001b[39m,sampling_rate)\n\u001b[0;32m      6\u001b[0m   \u001b[39m# Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:60\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mDeprecated as of librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mIt will be removed in librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,  \u001b[39m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     59\u001b[0m )\n\u001b[1;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:241\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    238\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[0;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[0;32m    243\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[0;32m    244\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ashu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\ashu\\\\Desktop\\\\voice-classifier/train_dataaudio_class_1.wav'"
          ]
        }
      ],
      "source": [
        "names = []\n",
        "features = []\n",
        "for x in train_data[0]:\n",
        "  names.append(str(x))\n",
        "  features.append(extract_features(x))\n",
        "train_data['mfcc']=features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "3lcayD-kq4K3",
        "outputId": "28b08357-a8f2-4303-ee98-29aa60669877"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d4c48d0e-9b79-46a7-92b6-ecfc1d701d24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>mfcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>audio_class_1.wav</td>\n",
              "      <td>([-3.6264037e-06, -9.355707e-06, -3.4309248e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>audio_class_2.wav</td>\n",
              "      <td>([-0.001233537, -0.000644137, 0.00021475347, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4c48d0e-9b79-46a7-92b6-ecfc1d701d24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4c48d0e-9b79-46a7-92b6-ecfc1d701d24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4c48d0e-9b79-46a7-92b6-ecfc1d701d24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   0                                               mfcc\n",
              "0  audio_class_1.wav  ([-3.6264037e-06, -9.355707e-06, -3.4309248e-0...\n",
              "1  audio_class_2.wav  ([-0.001233537, -0.000644137, 0.00021475347, -..."
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPSFVIlSN9HT"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggz5SA40RZUn"
      },
      "outputs": [],
      "source": [
        "#call modules for classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout \n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erGKSUTWRZRe"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(193, input_shape=(2,), activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.25))  \n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))    \n",
        "\n",
        "model.add(Dense(115, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvo-ug8SSUgx",
        "outputId": "0aafe0e3-11a3-431d-d45e-0c69b08fe29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 193)               579       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 193)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               24832     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 115)               14835     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,758\n",
            "Trainable params: 56,758\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVQ06wq6zixY"
      },
      "outputs": [],
      "source": [
        "X = np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uomu1bKRzx4D",
        "outputId": "cba5d621-4486-4054-f92c-897ace854102"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['audio_class_1.wav', 'audio_class_2.wav'], dtype='<U17')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.array(names)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKhCierk3I_w"
      },
      "outputs": [],
      "source": [
        "# X\n",
        "X_train = X[:90]\n",
        "y_train = y[:90]\n",
        "\n",
        "X_val = X[90:128]\n",
        "y_val = y[90:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFt9tE7RpfXG",
        "outputId": "5957dc31-a902-4772-c24a-43dbf04bd906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 128)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5xPspoeprEA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jokQ-jSv3J61",
        "outputId": "609d5b75-15d9-45e6-bcd5-476ad3b3ca33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['audio_class_1.wav', 'audio_class_2.wav'], dtype='<U17')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_quyvGRcbUOK",
        "outputId": "78d4793f-2946-4acc-d5b3-a81bbaff6058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling rate is :  22050\n"
          ]
        }
      ],
      "source": [
        "test_features = extract_features('/test_audio.wav',90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnsSzf4lziu8"
      },
      "outputs": [],
      "source": [
        "lb = LabelEncoder()\n",
        "y = to_categorical(lb.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9hbEEbVeGPG"
      },
      "outputs": [],
      "source": [
        "# X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1657bL3zipb",
        "outputId": "bc6b2acf-84eb-4ed7-e96c-7def02dea8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "print(len(X))\n",
        "print(len(X[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dPjvVpooDW0",
        "outputId": "750ffcfa-ee98-46b9-b5ec-dd81269c777b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmJngRcZzigy",
        "outputId": "0c40f192-a428-4beb-ac8e-7df0db91e7cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl5Dbd28rxNa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUMHI4A8r_1B"
      },
      "outputs": [],
      "source": [
        "# X_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "MwcTA95xRZPF",
        "outputId": "375e50ed-a9a8-4143-f723-eaf4248b1f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-676bf5ea7fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 128)\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sKQMPwDRZMe"
      },
      "outputs": [],
      "source": [
        "# Check out our train accuracy and validation accuracy over epochs.\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Set figure size.\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Generate line plot of training, testing loss over epochs.\n",
        "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
        "\n",
        "# Set title\n",
        "plt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n",
        "plt.xlabel('Epoch', fontsize = 18)\n",
        "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
        "plt.xticks(range(0,100,5), range(0,100,5))\n",
        "\n",
        "plt.legend(fontsize = 18);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RNIzYJzRZJl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo-NI0STRZGb"
      },
      "outputs": [],
      "source": [
        "# We get our predictions from the test data\n",
        "preds = model.predict_classes(test_features)\n",
        "# We transform back our predictions to the speakers ids\n",
        "preds = lb.inverse_transform(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaGMjSW289w4"
      },
      "source": [
        "**Data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-FkallxONZa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
